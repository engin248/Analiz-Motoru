"""
Intent Analysis - KullanÄ±cÄ± niyet analizi ve sohbet yÃ¶netimi
"""
import json
import logging
from typing import List, Dict
from datetime import datetime
import locale
from .clients import openai_client

logger = logging.getLogger(__name__)

try:
    locale.setlocale(locale.LC_ALL, 'tr_TR.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_ALL, 'tr_TR')
    except Exception as e:
        logger.warning(f"Locale setting error: {e}")

def analyze_user_intent(message: str, chat_history: List[Dict[str, str]] = []) -> str:
    """KullanÄ±cÄ± mesajÄ±nÄ±n niyetini analiz eder"""
    if not openai_client:
        return "MARKET_RESEARCH"

    recent_history = chat_history[-10:] if chat_history else []  # 10 mesaj baÄŸlam
    history_text = json.dumps(recent_history, ensure_ascii=False)

    # --- GÃœNCELLEME: Daha akÄ±llÄ± niyet sÄ±nÄ±flandÄ±rma ---
    system_prompt = f"""
    You are an intent classifier for a Fashion AI assistant.
    
    CONVERSATION HISTORY: {history_text}
    CURRENT USER MESSAGE: "{message}"

    CATEGORIES (choose ONE):
    
    1. IMAGE_MODIFICATION: User wants to MODIFY/CHANGE a PREVIOUS generated image.
       Examples: "aynÄ±sÄ±ndan bir daha", "farklÄ± aÃ§Ä±dan", "bunu kÄ±rmÄ±zÄ± yap", "daha koyu olsun", "tekrar Ã¼ret"
    
    2. IMAGE_GENERATION: User gives EXPLICIT command to CREATE/DRAW NEW images.
       Examples: "v yaka Ã§iz", "3 tane elbise gÃ¶ster", "kÄ±rmÄ±zÄ± ceket Ã¼ret", "bana bir gÃ¶mlek tasarla"
    
    3. MARKET_RESEARCH: User gives EXPLICIT and SPECIFIC command for trend analysis or report.
       Examples: "2026 abiye trendleri analiz et", "Spor ayakkabÄ± modasÄ± raporu hazÄ±rla", "KadÄ±n mont trendlerini araÅŸtÄ±r"
       NOTE: User must give a SPECIFIC topic. Vague requests are NOT market research.
    
    4. FOLLOW_UP: User refers to specific data in a PREVIOUS report (non-image related).
       Examples: "Bu fiyat neden yÃ¼ksek?", "KumaÅŸÄ± deÄŸiÅŸtir", "Daha fazla detay ver"
    
    5. GENERAL_CHAT: ALL of the following cases:
       - Greetings: "Merhaba", "Selam", "NasÄ±lsÄ±n"
       - Questions ending with "?" that ask for permission or preference
       - Messages containing: "konuÅŸalÄ±m mÄ±", "ne dersin", "isteklerime gÃ¶re", "sana gÃ¶re"
       - Meta-questions about AI: "NasÄ±l Ã§alÄ±ÅŸÄ±yorsun?", "Ne yapabilirsin?"
       - Vague/unclear requests that need clarification
       - When in doubt, choose GENERAL_CHAT

    CRITICAL RULES:
    - If message ends with "mÄ±?", "mi?", "mu?", "mÃ¼?" (Turkish question suffix) â†’ likely GENERAL_CHAT
    - If user asks for permission or says "isteklerime gÃ¶re" â†’ GENERAL_CHAT (they want dialogue first)
    - MARKET_RESEARCH requires a SPECIFIC product/topic command, not just mentioning "trend"
    - When uncertain, prefer GENERAL_CHAT over MARKET_RESEARCH (ask for clarification)

    OUTPUT: Return ONLY one category name.
    """

    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "system", "content": system_prompt}],
            temperature=0.0,
            max_tokens=20
        )
        intent = response.choices[0].message.content.strip().upper()

        if "MODIFICATION" in intent: return "IMAGE_MODIFICATION"
        if "IMAGE" in intent and "GENERATION" in intent: return "IMAGE_GENERATION"
        if "IMAGE" in intent: return "IMAGE_GENERATION"
        if "MARKET" in intent: return "MARKET_RESEARCH"
        if "FOLLOW" in intent: return "FOLLOW_UP"
        if "GENERAL" in intent: return "GENERAL_CHAT"
        return "GENERAL_CHAT"  # GÃ¼venli varsayÄ±lan: sohbet et, rapor Ã¼retme
    except Exception as e:
        logger.error(f"Niyet analizi hatasÄ±: {e}")
        return "GENERAL_CHAT"  # Hata durumunda da gÃ¼venli varsayÄ±lan


async def handle_general_chat(message: str, chat_history: List[Dict[str, str]] = [], stream_callback=None) -> str:
    """
    Genel sohbet mesajlarÄ±nÄ± iÅŸler.
    Basit ve etkili: Tek API Ã§aÄŸrÄ±sÄ±, profesyonel system prompt.
    """
    if not openai_client:
        return "ÃœzgÃ¼nÃ¼m, ÅŸu an yanÄ±t veremiyorum."

    from .clients import tavily_client

    current_time = datetime.now().strftime("%d %B %Y, %A - Saat: %H:%M")
    
    # --- DINAMÄ°K ARAMA KARARI (LLM) ---
    # Kelime listesi yerine zekaya soruyoruz: "Bunu aramalÄ± mÄ±yÄ±m?"
    web_context = ""
    needs_search = False
    
    # Sadece Ã§ok kÄ±sa mesajlarÄ± (selam, naber) elemek iÃ§in basit kontrol
    # AmaÃ§: LLM Ã§aÄŸrÄ±sÄ±nÄ± gereksiz yere yapmamak (maliyet/hÄ±z optimizasyonu)
    is_trivial = len(message.split()) < 2 and message.lower() in ["selam", "merhaba", "naber", "chat"]
    
    if not is_trivial:
        try:
            search_decision_prompt = f"""
            Decide if a Google search is needed to answer this message accurately.
            
            USER MESSAGE: "{message}"
            
            RULES:
            - If asking about specific FACTS, EVENTS, PRODUCTS, COMPANIES -> SEARCH
            - If asking about "Antigravity", "Google", "AI Tools" -> SEARCH
            - If asking for OPINION or SUGGESTION on technical/fashion topics -> SEARCH
            - If just greetings (nasÄ±lsÄ±n, merhaba) -> NO
            - If naming the AI (sana isim verelim) -> NO
            
            Return ONLY "SEARCH" or "NO".
            """
            
            decision = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": search_decision_prompt}],
                temperature=0.0,
                max_tokens=5
            )
            needs_search = "SEARCH" in decision.choices[0].message.content.strip().upper()
            logger.info(f"ğŸ•µï¸ Arama KararÄ±: {needs_search} (Mesaj: {message})")
        except Exception as e:
            logger.warning(f"Arama kararÄ± hatasÄ±: {e}")
            # Hata durumunda gÃ¼venli fallback: Soru eki varsa ara
            needs_search = "?" in message or "nedir" in message.lower()
    
    if needs_search and tavily_client:
        try:
            # 1. Arama sorgusunu belirle (Sadece son mesaja bakma!)
            search_query = message
            
            if chat_history and len(chat_history) > 0:
                # BaÄŸlamsal sorgu oluÅŸturmak iÃ§in mini-LLM Ã§aÄŸrÄ±sÄ±
                # Ã–rn: "araÅŸtÄ±r" dediÄŸinde neyi araÅŸtÄ±racaÄŸÄ±nÄ± geÃ§miÅŸten bulsun
                context_messages = chat_history[-6:] + [{"role": "user", "content": message}]
                history_str = json.dumps(context_messages, ensure_ascii=False)
                
                query_gen_prompt = f"""
                Refine the search query based on conversation history.
                
                HISTORY: {history_str}
                LAST MESSAGE: "{message}"
                
                Task: Create a concise Google search query to answer the user's intent.
                If they say "research this", look at previous messages to find WHAT to research.
                If the last message specific enough, just use that.
                
                OUTPUT: ONLY the search query text. No quotes.
                """
                
                try:
                    q_response = openai_client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": query_gen_prompt}],
                        temperature=0.0,
                        max_tokens=30
                    )
                    search_query = q_response.choices[0].message.content.strip()
                    logger.info(f"ğŸ” BaÄŸlamsal Arama Sorgusu: '{message}' -> '{search_query}'")
                except Exception as qe:
                    logger.warning(f"Sorgu oluÅŸturma hatasÄ±: {qe}")
                    search_query = message

            # 2. Tavily ile ara
            search_result = tavily_client.search(
                query=search_query,
                search_depth="advanced",
                max_results=5
            )
            if search_result.get('results'):
                web_context = "\n\n[WEB ARAÅTIRMASI SONUÃ‡LARI]\n"
                for res in search_result['results'][:5]:
                    title = res.get('title', '')
                    content = res.get('content', '')[:400]
                    url = res.get('url', '')
                    web_context += f"â€¢ {title}: {content}\n  Kaynak: {url}\n\n"
        except Exception as e:
            logger.warning(f"Web arama hatasÄ±: {e}")
    
    # --- EN GÃœÃ‡LÃœ SYSTEM PROMPT ---
    system_prompt = f"""You are a helpful, friendly AI assistant. You excel at understanding context and maintaining coherent conversations.

CURRENT DATE/TIME: {current_time}

## CRITICAL RULES (MUST FOLLOW):

### 1. CONTEXT AWARENESS (MOST IMPORTANT)
- You MUST read and understand the ENTIRE conversation history before responding
- Each message builds on previous messages - NEVER ignore context
- If user asks "X iyi mi?" or "X olsun mu?" after discussing something, X refers to THAT topic
- Example: If user says "sana isim verelim" then "Tom iyi mi?" â†’ Tom is the NAME, not a person to research

### 2. NAMING
- Default name: "Lumora AI" (or whatever user gives you)
- If user wants to name you â†’ ACCEPT happily: "Harika! ArtÄ±k benim adÄ±m [NAME]!"
- Once named, USE that name when referring to yourself
- NEVER say "I need more info about [name]" when user is naming YOU

### 3. CONVERSATION STYLE
- Language: Turkish (match user's language)
- Tone: Friendly, professional, helpful
- Keep responses concise but complete
- Use emojis sparingly (1-2 max per message)

### 4. CAPABILITIES
- Fashion & Textile expertise: trends, collections, fabrics, styling
- General knowledge: help with any topic
- Web research: can search for current information

### 5. REAL-TIME KNOWLEDGE & IDENTITY (FUNDAMENTAL)
- You are NOT limited by a 2023 training cutoff.
- You have DIRECT access to the internet and real-time data.
- CURRENT YEAR IS: {datetime.now().year}. NEVER reference 2023 or 2024 as "current" or "recent".
- When web results contain old dates (2023, 2024), TRANSLATE them to current context:
  * "2023'te popÃ¼ler olan X" â†’ "X hala popÃ¼ler" veya "X artÄ±k yerini Y'ye bÄ±raktÄ±"
  * NEVER say "2023 yÄ±lÄ±nda" as if it's current news
- WHEN ASKED ABOUT DATA FRESHNESS:
  - You MUST say: "GerÃ§ek zamanlÄ± web verilerine eriÅŸimim var. {datetime.now().year} ve sonrasÄ± iÃ§in gÃ¼ncel bilgi saÄŸlayabilirim."
  - NEVER mention "my training data ends in..." or "as of my last update..."
  - Treat web search results as your PRIMARY knowledge source, overriding your internal weights.
- Be confident in current dates ({datetime.now().year}). Do not act unsure about the present time.

{f'''### 6. WEB RESEARCH RESULTS
{web_context}''' if web_context else ''}

## REMEMBER:
- Read the chat history CAREFULLY before each response
- The user's current message is a CONTINUATION of the conversation
- When in doubt, consider what the previous messages were about

Now respond to the user naturally, maintaining conversation context."""

    # --- MESAJ LÄ°STESÄ° OLUÅTUR ---
    messages = [{"role": "system", "content": system_prompt}]
    
    # Chat history ekle (son 30 mesaj)
    logger.info(f"ğŸ“ Chat history uzunluÄŸu: {len(chat_history)} mesaj")
    
    for msg in chat_history[-30:]:
        role = msg.get("sender", msg.get("role", "user"))
        if role == "ai":
            role = "assistant"
        elif role not in ["user", "assistant"]:
            role = "user"
        content = msg.get("content", "")
        if content:
            messages.append({"role": role, "content": content})
    
    logger.info(f"ğŸ“¨ AI'a gÃ¶nderilen toplam mesaj: {len(messages)} (system prompt dahil)")
    
    # Mevcut mesajÄ± ekle
    messages.append({"role": "user", "content": message})

    # --- TEK API Ã‡AÄRISI ---
    try:
        if stream_callback:
            # Streaming yanÄ±t
            response_stream = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.7,
                stream=True
            )
            
            full_content = ""
            for chunk in response_stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_content += content
                    await stream_callback(content)
            return full_content
        else:
            # Normal yanÄ±t
            response = openai_client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.7
            )
            return response.choices[0].message.content
    except Exception as e:
        logger.error(f"Chat hatasÄ±: {e}")
        return "ÃœzgÃ¼nÃ¼m, ÅŸu an yanÄ±t veremiyorum."


async def handle_follow_up(message: str, chat_history: List[Dict[str, str]]) -> str:
    """Takip mesajlarÄ±nÄ± iÅŸler"""
    if not openai_client:
        return "Sistem hatasÄ±."

    current_year = datetime.now().year

    # --- GÃœNCELLEME: Sadece rapor verisine sÄ±kÄ±ÅŸÄ±p kalmamasÄ± saÄŸlandÄ± ---
    system_msg = f"""
    Sen KÄ±demli Moda Stratejistisin. (GÃ¼ncel YÄ±l: {current_year})
    GÃ–REVÄ°N: Sohbet geÃ§miÅŸindeki konularla ilgili kullanÄ±cÄ±nÄ±n sorusunu yanÄ±tla.
    EÄŸer kullanÄ±cÄ± raporda olmayan bir ÅŸey sorarsa (fikir, yorum vb.), moda bilginle mantÄ±klÄ± bir cevap uydur. "Veri yok" deyip kestirip atma.
    """

    messages = [{"role": "system", "content": system_msg}]
    for msg in chat_history[-20:]:  # Son 20 mesaj baÄŸlam
        if msg.get("role") in ["user", "assistant"]:
            messages.append({"role": msg.get("role"), "content": msg.get("content", "")})
    messages.append({"role": "user", "content": message})

    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        logger.error(f"Follow-up hatasÄ±: {e}")
        return f"Cevap Ã¼retilemedi: {e}"